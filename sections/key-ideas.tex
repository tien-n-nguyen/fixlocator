\subsection{Key Ideas}
\label{sec:key-ideas}

To address those challenges, we propose {\tool}, a novel FL approach
to locate all the CC fixing locations (i.e., faulty statements) that need
to be modified in a fix for a given bug. {\tool} has the following
novel key ideas in both new model and features:

{\bf Key Idea 1. [Dual Learning for Fault Localization]} To avoid the
confounding effect in a naive solution of detecting faulty methods
first and then detecting faulty statements in those methods, we design
an approach that treats detecting dependent CC fixing locations as a
{\em dual learning} task between them. First, the {\em method-level
  FL} model (\code{MethFL}) aims to learn the methods that need
to be modified in the same fix. Second, the {\em statement-level
  FL} model (\code{StmtFL}) aims to learn the co-fixing
statements regardless of whether they are in the same or different
methods.

Intuitively, \code{MethFL} and \code{StmtFL} are related to each
other, in which the results of one model can help the other. We refer
to this relation as {\em duality}, which can provide some useful
constraints for {\tool} to learn dependent CC fixing locations.
%
We conjecture that the joint training of the two models can improve
the performance of both models, when we leverage the constraints of
this duality in term of shared representations. For example, if two
statements in two different methods $m_1$ and $m_2$ were observed to
be changed in the same fix, then it should help the model learn that
$m_1$ and $m_2$ were also changed together to fix the bug.  If two
methods were observed to be fixed together, then some of their
statements were changed in the same fix as well. In our model, we
jointly train \code{MethFL} and \code{StmtFL} with the models'
parameter soft-sharing to exploit their relation. We use a mechanism
called {\em cross-stitch unit} to learn a linear combination of the
input features from two models to {\em enable the propagation of the impact
of \code{MethFL} on \code{StmtFL} and vice versa}.

%We also add an attention mechanism in the two models to help emphasize
%on the key features.


%Therefore, the third component is the {\em localization model} with
%the main goal of deriving the CC fixing locations. Another task of
%this component is to train the MethFL and StmtFL simultaneously to
%explot the duality. Specifically, we apply a probabilistic correlation
%as a regualization term in the foss function in the join training. We
%also design a novel constraint about the attention mechanism in two
%models.

%two dual regularization terms to constrain the duality of the two
%models, which are enlightened by the probabilistic correlation and the
%symmetry of attention weights between two models.




%{\bf Key Idea 3. [Multi-task Learning Fault Localization]} When doing the fault localization, there are often two levels of fault localization that we can do: the statement-level fault localization and the method-level fault localization. More detailed fault localization can help the developers to find the bugs easier. So for\tool, we regard the statement-level fault localization as our primary goal. However, the method fault localization is still helpful because the method-level fault localization often has higher accuracy and can help reduce the biases. 

%To make the method-level fault localization helpful when doing the statement-level fault localization, in \tool, we build a multi-task learning framework to do the statement-level fault localization. To be more specific, we have two separate models for the two levels of fault localization. The first model is to do the statement-level fault localization as we mentioned in key idea 2. And the second model is to do the method-level fault localization. In this model, we take the method pairs as input and train the model to predict if the method pairs are co-changes or not. During the training process, the parameters between the first and second models are softly shared to build the multi-task learning framework. We will introduce the details in the approach section.

{\bf Key Idea 2. [Co-Change Representation Learning]} In our problem
of detecting CC fixing locations, in addition to a new dual-learning
model in key idea 1, we also use a new feature: {\em co-change
  information}, i.e., the statements/methods that were changed
together. The co-changed statements/methods in the same commit are
used to train the two models. We also consider the co-fixed
statements/methods in the same fixes. The rationale for considering
general co-changes because those co-changed entities in the past might
become the ones that will be fixed together in the future.

%Just as we mentioned in observation 1, co-change is very common when
%we want to fix a bug or do an enhancement on the code. To catch the
%co-change information, we first collect the commits that change the
%source code. And for each commit, we mark the statements that changed
%together as the co-change. By collecting all co-changes from the
%commits in the project, we have a large co-change history
%dataset. Then, to analyze the code relationship, we build a link
%between the statements been changed together. To make the co-change
%information useful, we add these edges into the other graph to do the
%graph modeling. That is our second key idea.

{\bf Key Idea 3. [Graph Modeling for Dependencies among Statements/Methods]} The
statements/methods that need to be fixed together are
interdependent with several dependencies. Thus, we
use Graph-based Convolution Network (GCN)~\cite{li2019gcn} to model
different types of dependencies among the statements and methods,
e.g., data and control dependencies in a program dependence graph
(PDG), execution traces, stack traces, etc. For convenience, we also
encode the co-change relations among the statements into our graph
representations with different types of edges representing different
relations. The GCN model enables both nodes' and edges' attributes and
learns to classify the nodes as buggy or~not.

%{\bf Key Idea 2. [Multi-edge-types Graph Modeling]}

%As mentioned in observation 2, one bug can be involved in multiple
%methods, and for each method, there can be more than one statement
%related to the bug. To analysis the relationships between the
%statements that in the same method, the graph modeling between the
%source code such as program dependency graph (PDG), execution paths
%(EP), and co-change relationships (CCR) is the way that we thought to
%be suitable. To avoid overlapping, we regard the PDG as the based
%graph, add the EP and CCR edges into the graph, and use the combined
%graph to analyze the relationship.

%However, the different types of edges in one graph cannot be regarded as the same type. To specify the differences among the four different types of edges (PDG contains data dependency and control dependency, two types of edges), we use an advanced GCN \cite{li2019gcn} that takes both node and edge attributes as inputs to learn the node classification. Because it accepts edge attributes, we give the different types of edges with different labels as input to specify their differences.






