\section{Threats to Validity}
Our empirical evaluation has the following threats to validity. (1) We
evaluated {\tool} on Java and Python code. Our key modules are
language-independent and can be applied to other types of programming
languages.  (2) The compared baselines and {\tool} require a dataset
with test cases for generating code coverage information, run-time
information, and failing traces, thus we only compared them on three
datasets. In the future, we plan to test {\tool} on more types of
datasets. (3) DeepFL is designed for method-level FL. For a fair
comparison, we use only part of its features that are applicable to
statement level fault localization. The other baselines CNN-FL and
DeepRL4FL can be directly applied on statement-level FL. (4) To
compare fairly, we evaluated the baselines using our proposed
Hit-N@Set metric. However, we also evaluated {\tool} using the ranking
metric Hit-N@Top-$K$.

%{\tool} is consistently better than all baselines in any metric.


