\subsubsection{\bf RQ1. Comparison Results with State-of-the Art Baselines.}

As seen in Table~\ref{fig:rq1-0}, 
the comparison results show that {\tool} can outperform all baselines on locating faulty statements in every evaluation metric. Particularly, {\tool} can improve CNN-FL, DeepFL, and DeepRL4FL by 16.6\%, 16.9\%, and 9.9\% in terms of Hit-1@Set (the number of predicated sets contain at least 1 fault statement), respectively. Furthermore, when dealing with multiple faulty statements, {\tool} can improve CNN-FL, DeepFL, and DeepRL4FL by 33.6\%, 40.3\%, and 26.5\% in terms of Hit-2@Set, 43.9\%, 46.4\%, and 28.1\% in terms of Hit-3@Set, 100\%, 155.6\%, and 64.5\% in terms of Hit-4@Set, respectively. The Hit-N@set with N$\geq$2 is to evaluate the capabilities of detecting multiple fault statements and our results indicate that {\tool} locate more multiple statements in a set than any other baseline. The sizes of our predicated sets range from xx to xx with a median size xx. Thus, the Hit-5 and Hit5+ @Set are low as they are already bigger than our predicated sets. However, all other baselines also cannot work on the cases with N$\geq$5. Moreover, we can reduce the EXAM scores of baselines: CNN-FL, DeepFL, and DeepRL4FL by 22.2\%, 30\%, and 22.2\%, respectively, which indicates that {\tool} can reduce developers' efforts of finding the fault statements.

\begin{table}[t]
	\caption{RQ1. Comparison Results with Baselines.}
	{\small
		\begin{center}
			\renewcommand{\arraystretch}{1}
				\begin{tabular}{p{1.5cm}<{\centering}|p{1cm}<{\centering}|p{0.8cm}<{\centering}|p{1.2cm}<{\centering}|p{1.2cm}<{\centering}}
				\hline
				Metrics & CNN-FL & DeepFL & DeepRL4FL & \tool \\			
				\hline
				Hit-1@Set   & 332 & 331 & 352 & 387 \\
				Hit-2@Set	& 125 & 119 & 132 & 167 \\
				Hit-3@Set	& 57 & 56 & 64 & 82 \\
				Hit-4@Set	& 23 & 18 & 28 & 46 \\
				Hit-5@Set	& 5 & 4 & 6 & 9 \\
				Hit-5+@Set	& 1 & 2 & 3 & 3 \\
				Exam     	& 0.09 & 0.10 & 0.09 & 0.07 \\
				\hline
			\end{tabular}
			
			\label{fig:rq1-0}
		\end{center}
	}
\end{table}

Table~\ref{fig:rq1-1} shows the breakdown results of Hit-N@Set and Exam Score for localizing faulty statement for each type of faults. We classify the faults into 6 categories using their associated number of fault statements: faults with K fault statements, K = 1, 2, 3, 4, 5, and 5+. {\tool} can outperform all baselines using any evaluation metric when dealing with any type of faults. Especially, when dealing with the faults with a number of faulty statements$le$4, {\tool} can locate more faulty statements than baselines.

\begin{table}[t]
	\caption{RQ1. Detailed Results on Each Type of Faults Classified using \# of Faulty Statements.}
	{\small
		\begin{center}
			\renewcommand{\arraystretch}{1}
			\begin{tabular}{p{0.8cm}<{\centering}|p{1.33cm}<{\centering}|p{1cm}<{\centering}|p{0.7cm}<{\centering}|p{1cm}<{\centering}|p{1cm}<{\centering}}
				\hline
				Type& Metrics & CNN-FL & DeepFL & DeepRL4FL & \tool \\
				\hline
				\multirow{3}{*}{1 (199)}   & Hit-1@set     & 78 & 76 & 84 & 93 \\
							    		 & EXAM          & 0.09 & 0.09 & 0.08 & 0.06 \\
									% & EXAM\_AVG     & 0.09 & 0.09 & 0.08 & 0.06 \\
				\hline
				\multirow{4}{*}{2 (142)}  & Hit-1@set     & 67 & 64 & 70 & 75 \\
										& Hit-2@set     & 33 & 30 & 34 & 41 \\
									   	& EXAM          & 0.09 & 0.10 & 0.09 & 0.08 \\
			                     %	& EXAM\_AVG     & 0.22 & 0.23 & 0.19 & 0.15 \\
				\hline
				\multirow{5}{*}{3 (90)}  & Hit-1@set     & 46 & 44 & 47 & 51 \\
										& Hit-2@set     & 21 & 20 & 23 & 25\\
										& Hit-3@set     & 11 &10 & 13 & 21 \\
										& EXAM          & 0.11 & 0.12 & 0.11 & 0.09 \\
								%	& EXAM\_AVG     & 0.33 & 0.31 & 0.27 & 0.21 \\
				\hline
				\multirow{6}{*}{4 (78)}  & Hit-1@set     & 41 & 42 & 42 & 45 \\
										& Hit-2@set     &22 & 19 & 21 & 24 \\
										& Hit-3@set     & 9 & 7 & 8 & 12 \\
										& Hit-4@set     & 3 & 2 & 4 & 9 \\
										& EXAM          & 0.07 & 0.08 & 0.07 & 0.06 \\
								%	& EXAM\_AVG     & 0.39 & 0.44 & 0.38 & 0.34 \\
				\hline
				\multirow{7}{*}{5 (43)}  & Hit-1@set     & 15 & 14 & 16 & 18 \\
										& Hit-2@set     & 9 & 8 & 9 & 12 \\
										& Hit-3@set     & 6 & 5 & 6 & 7 \\
										& Hit-4@set     & 3 & 2 & 3 & 3 \\
										& Hit-5@set     & 1 & 1 & 1 & 1 \\
										& EXAM          & 0.08 & 0.09 & 0.08 & 0.08 \\
								%	& EXAM\_AVG     & 0.47 & 0.51 & 0.45 & 0.39 \\
				\hline
				\multirow{8}{*}{5+ (283)}  & Hit-1@set     & 85 & 91 & 93 & 105 \\
								 		& Hit-2@set     & 40 & 42 & 45 & 65 \\
										& Hit-3@set     & 31 & 34 & 37 & 42 \\
								 		& Hit-4@set     & 17 & 14 & 21 & 34 \\
										& Hit-5@set     & 4 & 3 & 5 & 8 \\
										& Hit-5+@set    & 1 & 2 & 3 & 3 \\
										& EXAM          & 0.11 & 0.11 & 0.10 & 0.09 \\
								%	& EXAM\_AVG     & 0.65 & 0.73 & 0.68 & 0.62 \\
				\hline
			\end{tabular}
			
			\label{fig:rq1-1}
		\end{center}
	}
\end{table}

%tips:

%1. The exam and exme\_avg score is the lower the better

%2. The hit@set is the higher the better

%2. \tool is the best performed approach



\begin{table}[t]
	\caption{RQ1. Comparison Results with Baselines using Hit-N@Top-K.}
	{\small
		\begin{center}
			\renewcommand{\arraystretch}{1}
			\begin{tabular}{p{1.5cm}<{\centering}|p{0.3cm}<{\centering}|p{0.3cm}<{\centering}|p{0.3cm}<{\centering}|p{0.2cm}<{\centering}|p{0.2cm}<{\centering}|p{0.3cm}<{\centering}|p{0.3cm}<{\centering}|p{0.3cm}<{\centering}|p{0.2cm}<{\centering}|p{0.2cm}<{\centering}|p{0.2cm}<{\centering}}
				\hline
				\multirow{2}{*}{Approach}    & \multicolumn{5}{c|}{Hit-n@Top5}& \multicolumn{6}{c}{Hit-n@Top10}\\
				\cline{2-12}
											 &1&2&3&4&5&1&2&3&4&5&5+\\
				
				\hline
				CNN-FL      & 533 & 311 & 133 & 33 & 4 & 578 & 386 & 166 & 42 & 10 & 81 \\
				DeepFL		& 525 & 298 & 131 & 35 & 6 & 563 & 364 & 156 & 42 & 10 & 83 \\
				DeepRL4FL	& 586 & 339 & 159 & 32 & 9 & 623 & 407 & 186 & 48 & 13 & 92 \\
				\hline
				\tool       & 633 & 420 & 195 & 46 & 11& 690 & 470 & 217 & 51 & 13 & 94 \\
				\hline
			\end{tabular}
			
			\label{fig:rq1-2}
		\end{center}
	}
\end{table}

Table~\ref{fig:rq1-2} shows that {\tool} can locate more faulty statements than any other compared baseline using the evaluation metrics: Hit-N@Top-5 and Hit-N@Top-10. The results indicate that even in the ranking setting, {\tool} can still locate more faulty statements than any other baselines, especially dealing multiple faulty statements relevant to faults. For example, {\tool} can improve the best performing baseline DeepRL4RL by 23.9\% in Hit-2@Top-5, 22.6\% in Hit-3@Top-5, 43.8\% in Hit-4@Top-5, and 22.2\% in Hit-5@Top-5, respectively. The results for Hit-N@Top-10 share the similar trend as the ones for Hit-N@Top-5. 
