\subsubsection{\bf RQ1. Comparison with State-of-the-Art DL-based FL Approaches.}
\label{sec:rq1-result}

\begin{table}[t]
	\caption{RQ1. Detailed Comparison Results on Each Type of Faults Classified based on \# of CC Fixing Statements.}
	\vspace{-10pt}
        \tabcolsep 2pt
	{\small
		\begin{center}
			\renewcommand{\arraystretch}{1}
			\begin{tabular}{p{1.3cm}<{\centering}|p{0.8cm}<{\centering}|p{1cm}<{\centering}|p{0.8cm}<{\centering}|p{1.3cm}<{\centering}|p{1cm}<{\centering}|p{1.3cm}<{\centering}}
				\hline
				\#CC-Stmts & Metrics & CNN-FL & DeepFL & DeepRL4FL & DEAR & \tool \\
				\hline
				\multirow{1}{*}{1 (199 bugs)}   & Hit-1  & 78 & 76 & 84 & & 93 \\
%				& EXAM          & 0.16 & 0.16 & 0.15 & 0.08 \\
				\hline
				\multirow{2}{*}{2 (142 bugs)}  & Hit-1   & 67 & 64 & 70 & & 75 \\
				& Hit-2         & 33 & 30 & 34 & & 41 \\
%				& EXAM          & 0.15 & 0.18 & 0.17 & 0.11 \\
				\hline
				\multirow{3}{*}{3 (90 bugs)}  & Hit-1    & 46 & 44 & 47 & & 51 \\
				& Hit-2     & 21 & 20 & 23 & & 25\\
				& Hit-3     & 11 &10 & 13 & & 21 \\
%				& EXAM          & 0.17 & 0.19 & 0.19 & 0.12 \\
				\hline
				\multirow{4}{*}{4 (78 bugs)}  & Hit-1    & 41 & 42 & 42 & & 45 \\
				& Hit-2     &22 & 19 & 21 & & 24 \\
				& Hit-3     & 9 & 7 & 8 & & 12 \\
				& Hit-4     & 3 & 2 & 4 & & 9 \\
%				& EXAM          & 0.1 & 0.13 & 0.11 & 0.09 \\
				\hline
				\multirow{5}{*}{5 (43 bugs)}  & Hit-1    & 15 & 14 & 16 & & 18 \\
				& Hit-2     & 9 & 8 & 9 & & 12 \\
				& Hit-3     & 6 & 5 & 6 & & 7 \\
				& Hit-4     & 3 & 2 & 3 & & 3 \\
				& Hit-5     & 1 & 1 & 1 & & 1 \\
%				& EXAM          & 0.12 & 0.14 & 0.14 & & 0.10 \\
				\hline
				\multirow{6}{*}{5+ (283)}  & Hit-1 & 85 & 91 & 93 & & 105 \\
				& Hit-2     & 40 & 42 & 45 & & 65 \\
				& Hit-3     & 31 & 34 & 37 & & 42 \\
				& Hit-4     & 17 & 14 & 21 & & 34 \\
				& Hit-5     & 4 & 3 & 5 & & 8 \\
				& Hit-5+    & 1 & 2 & 3 & & 3 \\
%				& EXAM          & 0.14 & 0.20 & 0.13 & 0.11 \\
				\hline
			\end{tabular}
			
			\label{fig:rq1-details}
		\end{center}
	}
\end{table}

\begin{table}[t]
	\caption{RQ1. Comparison Results with DL-based FL Models}
	\vspace{-10pt}
	{\small
		\begin{center}
			\renewcommand{\arraystretch}{1}
			\begin{tabular}{p{1.2cm}<{\centering}|p{1cm}<{\centering}|p{0.8cm}<{\centering}|p{1.2cm}<{\centering}|p{1cm}<{\centering}|p{1.2cm}<{\centering}}
				\hline
				Metrics & CNN-FL & DeepFL & DeepRL4FL & DEAR & \tool \\			
				\hline
				Hit-1   & 332 & 331 & 352 & & 387 \\
				Hit-2	& 125 & 119 & 132 & & 167 \\
				Hit-3	& 57 & 56 & 64 & & 82 \\
				Hit-4	& 23 & 18 & 28 & & 46 \\
				Hit-5	& 5 & 4 & 6 & & 9 \\
				Hit-5+	& 1 & 2 & 3 & & 3 \\
                                Hit-All & 127  & 121  & 139  & & 168\\
%				EXAM    & 0.14 & 0.18 & 0.15 & 0.09 \\
				\hline
			\end{tabular}
			
			\label{fig:rq1-overview}
		\end{center}
	}
\end{table}

Table~\ref{fig:rq1-details} shows the result for the bugs in the
oracle with {\em different numbers $K$ of CC fixing statements}: $K$=
$CCStmts$ = 1, 2, 3, 4, 5, and 5+. For example, in the oracle, there
are 90 bugs with 3 faulty statements. {\tool}'s predicted set
correctly contains all 3 statements for 21 bugs (Hit-All), 2 of them
for 25 bugs, and 1 faulty statement for 51 bugs. As seen, regardless
of $N$, {\tool} performs better in any Hit-$N$ over the baselines for
all $K$s. Note that Hit-All = Hit-$N$ when $N$ (\#overlaps) = $K$ (\#CC-Stmts).


%As seen, {\tool} improves over the baselines in any metric when
%dealing with any number of faulty statements. For the bugs with
%$\leq$5 faulty statements, {\tool} locates more faulty statements than
%any baseline.

Table~\ref{fig:rq1-overview} shows the summary of the comparison
results in which we sum all the corresponding Hit-$N$ values for
different numbers $K$ of CC fixing statements in
Table~\ref{fig:rq1-details}.
%
%As seen in Table~\ref{fig:rq1-0}, the comparison results show that
%{\tool} can improve over all baselines on locating CC fixing
%statements in every evaluation metric. Particularly,
As seen, {\tool} can improve over CNN-FL, DeepFL, DeepRL4FL, and DEAR
by {\bf 16.6\%, 16.9\%, 9.9\%, and xx.x\%}, respectively, in terms of
Hit-1 (i.e., the predicted set contains $\geq 1$ faulty statement).
%
%Hit-N@Set with N$\geq$2 aims to evaluate the capability of detecting
%multiple CC fixing statements. As seen, {\tool} locates more multiple
%statements in a set than any baseline. Specifically,
%
It also improves over the baselines by 33.6\%, 40.3\%, 26.5\%,
and {\bf xx.x\%} in terms of Hit-2, 43.9\%, 46.4\%, 28.1\%, and {\bf
xx.x\%} in terms of Hit-3, 100\%, 155.6\%, 64.5\%, and {\bf xx.x\%} in
terms of Hit-4, respectively. Note: Hit-$N$ (including Hit-1) reflects
the cases of multiple CC statements.
%
Importantly, our tool produced the exact-match sets for 168/864 bugs
(19.5\%), relatively improving over the baselines 32\%, 38.8\%,
20.8\%, and {\bf xx.x\%} in Hit-All. It performs well in Hit-All
when the number of CC statements $K$=1-4. However, producing the
exact-matched sets for all statements when $K \geq 5$ is still
challenging for all models.

%Tien removed this para
%The sizes of our predicted sets range from 1
%to 8 statements with a median size of 3 and a mean size of 3.48. 75\%
%of the sets have a size from 3-5 statements. Thus, {\tool} detects CC
%fixing locations well for the common cases in terms of the number of
%faulty statements, while it is still challenging for all models for
%the cases of more than 5 faulty statements.

%Thus, Hit-5@Set and Hit5+@Set are low as they are already larger than
%our predicted sets. However, all other baselines also cannot work on
%the cases with N$\geq$5.

%Tien removed this EXAM para
%{\tool} also reduces EXAM scores compared to the baselines CNN-FL,
%DeepFL, and DeepRL4FL by 22.2\%, 30\%, and 22.2\%, respectively. Thus,
%{\tool} saves more human efforts in searching for the CC fixing
%statements than the baselines.







%tips:

%1. The exam and exme\_avg score is the lower the better

%2. The hit@set is the higher the better

%2. \tool is the best performed approach



\begin{table}[t]
	\caption{RQ1. Comparison with Baselines in Hit-N@Top-$K$.}
        \vspace{-6pt}
	{\small
		\begin{center}
			\renewcommand{\arraystretch}{1}
			\begin{tabular}{p{1.5cm}<{\centering}|p{0.3cm}<{\centering}|p{0.3cm}<{\centering}|p{0.3cm}<{\centering}|p{0.2cm}<{\centering}|p{0.2cm}<{\centering}|p{0.3cm}<{\centering}|p{0.3cm}<{\centering}|p{0.3cm}<{\centering}|p{0.2cm}<{\centering}|p{0.2cm}<{\centering}|p{0.2cm}<{\centering}}
				\hline
				\multirow{2}{*}{Model}    & \multicolumn{5}{c|}{Hit-N@Top5}& \multicolumn{6}{c}{Hit-N@Top10}\\
				\cline{2-12}
											 &1&2&3&4&5&1&2&3&4&5&5+\\
				
				\hline
				CNN-FL      & 533 & 311 & 133 & 33 & 4 & 578 & 386 & 166 & 42 & 10 & 81 \\
				DeepFL		& 525 & 298 & 131 & 35 & 6 & 563 & 364 & 156 & 42 & 10 & 83 \\
				DeepRL4FL	& 586 & 339 & 159 & 32 & 9 & 623 & 407 & 186 & 48 & 13 & 92 \\
				\hline
				\tool       & 633 & 420 & 195 & 46 & 11& 690 & 470 & 217 & 51 & 13 & 94 \\
				\hline
			\end{tabular}
			
			\label{fig:rq1-2}
		\end{center}
	}
\end{table}

Table~\ref{fig:rq1-2} shows the comparison result in Hit-N@Top-$K$.
As seen, {\tool} can locate more faulty statements than any baseline
in Hit-N@Top-5 and Hit-N@Top-10. The results indicate that even in the
ranking setting, {\tool} locates more faulty statements than
any other baseline, especially dealing multiple faulty statements. For
example, {\tool} improves the best performing baseline DeepRL4RL by
23.9\% in Hit-2@Top-5, 22.6\% in Hit-3@Top-5, 43.8\% in Hit-4@Top-5,
and 22.2\% in Hit-5@Top-5, respectively. The Hit-N@Top-10 result has
the same trend as Hit-N@Top-5 in which {\tool} improves over the
baselines.

We did not compare with the spectrum-based and mutation-based FL
models since DeepRL4FL~\cite{icse21-fl} was shown to outperform
those approaches. Thus, our result shows that {\tool}
could improve over those spectrum-/mutation-based FL approaches.
